{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvlT4lXE09rO"
      },
      "source": [
        "# Transformer Using Pytroch\n",
        "Transformers have revolutionized the field of Natural Language Processing (NLP) by introducing a novel mechanism for capturing dependencies within sequences through attention mechanisms. Let’s break it down, implement it from scratch using PyTorch.\n",
        "\n",
        "\n",
        "The implementation is based on the paper: [*Attention Is All You Need!*](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*BHzGVskWGS_3jEcYYi6miQ.png\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RGVXkdEwrTnp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLRKuNbs2Zub"
      },
      "source": [
        "## Input Embedding\n",
        "\n",
        "It allows to convert the original sentence into a vector of X dimensions (d_model in our case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaMFdNCtrrMT"
      },
      "outputs": [],
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) * math.sqrt(x.size(-1))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB9Kdnxw2ghd"
      },
      "source": [
        "## PositionalEncoding Class\n",
        "\n",
        "Positional encoding is a crucial component in transformer models, which helps the model understand the position of each word in a sentence.\n",
        "\n",
        "**Mathematical Formulation:**\n",
        "\n",
        "For a given position *pos* and embedding dimensoin i:\n",
        "\n",
        "$PE_{(pos,2i)}=sin(\\frac{pos}{(10000^{(2i/d_{model})}}) $\n",
        "\n",
        "$PE_{(pos,2i+1)}=cos(\\frac{pos}{(10000^{(2i/d_{model})}}) $\n",
        "\n",
        "where:\n",
        "\n",
        "- $PE_{(pos,2i)}$ is the value of the positional encoding at position *pos* for the even dimenstion 2i.\n",
        "- $PE_{(pos,2i+1)}$ is the value of the positional encoding at position *pos* for the odd dimension 2i + 1.\n",
        "- $d_{model}$ is the dimension of the embedding (e.g. 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6QzYStmtEWR"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        position = torch.arange(seq_len).unsqueeze(1)  # [seq_len, 1]\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # even indices\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # odd indices\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:seq_len, :].unsqueeze(0)  # broadcast to [batch_size, seq_len, d_model]\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL7UXmRS6JGA"
      },
      "source": [
        "## FeedForwardBlock Class\n",
        "\n",
        "FeedForward is basically a fully connected layer, that transformer uses in both encoder and decoder. It consists of two linear transformations with a ReLU activation in between. This helps in adding non-linearity to the model, allowing it to learn more complex patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TvahI2uAuAaR"
      },
      "outputs": [],
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff) # w1 and b1\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model) # w2 and b2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n",
        "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98waP0ja8tFm"
      },
      "source": [
        "## MultiHeadAttentionBlock Class\n",
        "\n",
        "Multi-head attention is a core component of the transformer architecture, enabling the model to focus on different parts of the input sequence simultaneously. Let’s break down how multi-head attention works and why it is essential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRtPcu3hue1J"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        assert d_model % h == 0, \"d_model must be divisible by number of heads h\"\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
        "        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        \n",
        "        # (batch, h, seq_len, d_k) x (batch, h, d_k, seq_len) = (batch, h, seq_len, seq_len)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)  \n",
        "\n",
        "        if dropout is not None:\n",
        "            attn = dropout(attn)\n",
        "\n",
        "        output = torch.matmul(attn, value)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, x_q, x_k, x_v, mask):\n",
        "        Q = self.w_q(x_q)  \n",
        "        K = self.w_k(x_k)  \n",
        "        V = self.w_v(x_v)  \n",
        "\n",
        "        batch_size = x_q.size(0)\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, -1, self.h, self.d_k).transpose(1, 2) \n",
        "        V = V.view(batch_size, -1, self.h, self.d_k).transpose(1, 2) \n",
        "\n",
        "        \n",
        "        out = self.attention(Q, K, V, mask, self.dropout)\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        out = self.w_o(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i--xC53VCGHX"
      },
      "source": [
        "## ResidualConnection Class\n",
        "\n",
        "Residual connections, or skip connections, are used to help with the training of deep neural networks by allowing gradients to flow more easily through the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mshJx_DXutDi"
      },
      "outputs": [],
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, Y):\n",
        "        return self.norm(x + self.dropout(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VudrG2kH77r9"
      },
      "source": [
        "## EncoderBlock Class\n",
        "\n",
        "Now we will create the encoder block which will contain one multi-head attention, two Add and Norm (ResidualConnection) & one feed forward layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH9ACC1CutsS"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention = self_attention_block\n",
        "        self.residual1 = ResidualConnection(d_model, dropout)\n",
        "        self.feed_forward = feed_forward_block\n",
        "        self.residual2 = ResidualConnection(d_model, dropout)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        attn_output = self.self_attention(x, x, x, src_mask)\n",
        "        x = self.residual1(x, attn_output)\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.residual2(x, ff_output)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Fb0TltCcwJRT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model: int, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPlNbFlY8SUE"
      },
      "source": [
        "## DecoderBlock Class (30)\n",
        "\n",
        "The `DecoderBlock` class represents a single block of the Transformer decoder. Each decoder block contains a self-attention mechanism, a cross-attention mechanism (attending to the encoder's output), and a feed-forward network, all surrounded by residual connections and layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceXVV6kHwcp9"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model: int,\n",
        "                 self_attention_block: MultiHeadAttentionBlock,\n",
        "                 cross_attention_block: MultiHeadAttentionBlock,\n",
        "                 feed_forward_block: FeedForwardBlock,\n",
        "                 dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention = self_attention_block\n",
        "        self.cross_attention = cross_attention_block\n",
        "        self.feed_forward = feed_forward_block\n",
        "        self.residual1 = ResidualConnection(d_model, dropout)\n",
        "        self.residual2 = ResidualConnection(d_model, dropout)\n",
        "        self.residual3 = ResidualConnection(d_model, dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        self_attn_output = self.self_attention(x, x, x, tgt_mask)  \n",
        "        x = self.residual1(x, self_attn_output)   \n",
        "        cross_attn_output = self.cross_attention(x, encoder_output, encoder_output, src_mask)\n",
        "        x = self.residual2(x, cross_attn_output)   \n",
        "        ff_output = self.feed_forward(x)   \n",
        "        x = self.residual3(x, ff_output)  \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GSxFumIPw8UB"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = nn.LayerNorm(features)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdCiuDDh8pt6"
      },
      "source": [
        "## Projection Layer Class\n",
        "\n",
        "The `ProjectionLayer` class is used to convert the high-dimensional vectors (output of the decoder) into logits over the vocabulary. This projection is typically the last layer in the decoder of a transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1fhsEEQxxSI5"
      },
      "outputs": [],
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x) -> None:\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDkoVnql9gTx"
      },
      "source": [
        "## Transformer Class (50)\n",
        "\n",
        "The `Transformer` class encapsulates the entire transformer model, integrating both the encoder and decoder components along with embedding layers and positional encodings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxpbUIeYxWeB"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: Encoder,\n",
        "                 decoder: Decoder,\n",
        "                 src_embed: InputEmbeddings,\n",
        "                 tgt_embed: InputEmbeddings,\n",
        "                 src_pos: PositionalEncoding,\n",
        "                 tgt_pos: PositionalEncoding,\n",
        "                 projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor) -> torch.Tensor:\n",
        "        src_embeddings = self.src_embed(src)   \n",
        "\n",
        "        \n",
        "        src_embeddings = self.src_pos(src_embeddings)  \n",
        "\n",
        "        encoder_output = self.encoder(src_embeddings, src_mask) \n",
        "        return encoder_output\n",
        "\n",
        "    def decode(self,\n",
        "               encoder_output: torch.Tensor,\n",
        "               src_mask: torch.Tensor,\n",
        "               tgt: torch.Tensor,\n",
        "               tgt_mask: torch.Tensor) -> torch.Tensor:\n",
        "        tgt_embeddings = self.tgt_embed(tgt)  \n",
        "        tgt_embeddings = self.tgt_pos(tgt_embeddings)   \n",
        "        decoder_output = self.decoder(tgt_embeddings, encoder_output, src_mask, tgt_mask)  \n",
        "        return decoder_output\n",
        "\n",
        "    def project(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # (batch, seq_len, vocab_size)\n",
        "        return self.projection_layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd7jslb9wlr"
      },
      "source": [
        "## Build Transformer Function (50)\n",
        "\n",
        "`build_transformer` constructs a full Transformer model by putting together its various components, such as embedding layers, positional encoding, encoder and decoder blocks, and a final projection layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3Wsq2CJxYuy"
      },
      "outputs": [],
      "source": [
        "def build_transformer(src_vocab_size: int,\n",
        "                      tgt_vocab_size: int,\n",
        "                      src_seq_len: int,\n",
        "                      tgt_seq_len: int,\n",
        "                      d_model: int=512,\n",
        "                      N: int=6,\n",
        "                      h: int=8,\n",
        "                      dropout: float=0.1,\n",
        "                      d_ff: int=2048,\n",
        "                      device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> Transformer:\n",
        "   \n",
        "\n",
        "    src_embed = InputEmbeddings(d_model=d_model, vocab_size=src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model=d_model, vocab_size=tgt_vocab_size)\n",
        "\n",
        "     \n",
        "    src_pos = PositionalEncoding(d_model=d_model, seq_len=src_seq_len, dropout=dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model=d_model, seq_len=tgt_seq_len, dropout=dropout)\n",
        "\n",
        "     \n",
        "    encoder_layers = nn.ModuleList([\n",
        "        EncoderBlock(d_model=d_model,\n",
        "                    self_attention_block=MultiHeadAttentionBlock(d_model=d_model, h=h, dropout=dropout),\n",
        "                    feed_forward_block=FeedForwardBlock(d_model=d_model, d_ff=d_ff, dropout=dropout),\n",
        "                    dropout=dropout)\n",
        "        for _ in range(N)\n",
        "    ])  \n",
        "\n",
        "     \n",
        "    decoder_layers = nn.ModuleList([\n",
        "        DecoderBlock(d_model=d_model,\n",
        "                    self_attention_block=MultiHeadAttentionBlock(d_model=d_model, h=h, dropout=dropout),\n",
        "                    cross_attention_block=MultiHeadAttentionBlock(d_model=d_model, h=h, dropout=dropout),\n",
        "                    feed_forward_block=FeedForwardBlock(d_model=d_model, d_ff=d_ff, dropout=dropout),\n",
        "                    dropout=dropout)\n",
        "        for _ in range(N)\n",
        "    ])\n",
        "\n",
        "    encoder = Encoder(d_model=d_model, layers=encoder_layers).to(device)\n",
        "    decoder = Decoder(features=d_model, layers=decoder_layers).to(device)\n",
        "\n",
        "    projection_layer = ProjectionLayer(d_model=d_model, vocab_size=tgt_vocab_size).to(device)\n",
        "\n",
        "    transformer = Transformer(encoder=encoder,\n",
        "                              decoder=decoder,\n",
        "                              src_embed=src_embed,\n",
        "                              tgt_embed=tgt_embed,\n",
        "                              src_pos=src_pos,\n",
        "                              tgt_pos=tgt_pos,\n",
        "                              projection_layer=projection_layer).to(device)\n",
        "\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS_k_WiyiIUe"
      },
      "source": [
        "## Testing the model\n",
        "\n",
        "Here is a simple test to verify whether I have implemented the transformer correctly. Run the code below and ensure that both the training and validation losses decrease steadily.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfiVMG0ojC1n",
        "outputId": "ebe3fe10-c8eb-4e8e-8c50-abc0498811b6"
      },
      "outputs": [],
      "source": [
        "!pip install datasets sentencepiece transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702,
          "referenced_widgets": [
            "3d2f465ce6f547f8a069a172cd236d97",
            "5132788d9e77434eb5926394654f8604",
            "e408c0ec8f3f4529b6b3274360f8fd16",
            "5d8e5bf6f63b4dbda4155cde4f564c8f",
            "75557100220d4bad98d4a002ed9b093d",
            "6e85e5a9db7e449697ec09b53c4d9a03",
            "b95c85cbd15b4e0ea0143af5afbb124c",
            "5699cff05c7047fbbd2b7b33ddde2e6c",
            "af32b2077f4f4078be912e72641d156c",
            "4761889fcd6445959f7d41ee6ee95cac",
            "396878c255f7402888fa3bff8a07e0ae",
            "5c321a284125486a8b005004694d2523",
            "0ab3ae24200046b685a36d2e9a3b6100",
            "44a957604e4c4430b22134f51c0fe973",
            "9274e7148f984585affb9cc506a179d5",
            "61d3ca12738f4456a841fb14b13413bd",
            "95ac0effa5f94ff7ab6e3bcf1236f913",
            "6c0076bbe5754fb7ac84e7208fc4985f",
            "b3ea0e4dc4ce4b5bb97019455d21d9ef",
            "ac11ae0be0cb4fbc8b662847924a32b5",
            "3497ad3d9ffc457c89ac54e5f563a08a",
            "9c777f9556044b6790cbf4b460db86d2",
            "6431922472ef4cdb9e382aa49ca65421",
            "9c663ed234324c7387f5ac5fc090f513",
            "9ec5cffa3ef74a38a18d1243a348f2cc",
            "5b177633cd1f472cb17a6debdcf36629",
            "f60ade14fddd40b39544f370f962b07a",
            "f5d058e9926345e4a59e79942086de7c",
            "e52c70a411804faea54c240759585d78",
            "9583af9d03944bffab294195d4e89782",
            "1abe30b43e9d464f9100ab2caf3e6dd7",
            "75fe40ade8fc4a7b80e74cf92ee05e4c",
            "ff63f138d61c4d6da72c76a4763571b9",
            "4202bc6c058b499d9d438a22c85224e6",
            "ac4a8e84aeca4bc183a3312f9e877a6d",
            "8ed9c3e5374848a38156dc7cefbf4605",
            "ec6707e5cbd04583b5155bf1b5cd6977",
            "cdbe35981e194268b6eb8e2ade190488",
            "c80edddb9006477aa7888e500222d799",
            "27673438d9c346d9beb1f31408639482",
            "8e1da2d83914413fac0bfe3146dd2c8b",
            "7650ba0bbdf84b689ec805ff9989f7cd",
            "1079691f2b554083ac59fa9f0750c095",
            "763183e391ce43ae9976bdeb8cb876c7",
            "777ed2f23db446f2b7565800c55eb157",
            "1967594006b9445ca38b581f45f73209",
            "86c608e6b56a4ad394d9d8bfd5abcfef",
            "90ce84eb0eb9479fa69da58643470326",
            "f4dfd807dea4492dba8078eacfe45e0d",
            "df81971945b24e65bee3efe239d20193",
            "be4c08e8a9e74781964408398e7508f7",
            "80d775b55f62439d947aaa84aa27f150",
            "773af3d6136f4e5c922743b2026c98ff",
            "dcf6e2e4f5eb4bcda19332fd14a0de27",
            "a5b9d3d01d6245e999e82c51e75fd748",
            "5fdf089e0d2f450c8c997d99f1d617fb",
            "2a00bb97312041b6b08318baea4f4b55",
            "c2d3d9068b1c4d8987ea1909a2241822",
            "22af993ce596441fa2255920386cb5c8",
            "cb4d682f70754f749d3df13217a020d4",
            "8bc225647c654618b3a5548ce86c981d",
            "f00fe7869bc141b5bdeef29034652cb5",
            "10ab3ec196e54b63b56df82204675d77",
            "437795b1ba784371a276590a7b5735ab",
            "824f50140ee5412fa14eac47119cf57c",
            "3fa2bfc9ee6b49f7a0401c6156c39a1c",
            "e0f0959c0a144822b685e06306699512",
            "5fa7c514ac2346bd8259eb696a554f63",
            "afe1ef7c2d534630a3c14de4559f8fa1",
            "666d6aa5fcae41149356f39fa1290e5f",
            "969141c91ed5417292442b77f7c75615",
            "f9e4ecdbba6145078e8a92c06bc271f7",
            "22745c3dd7e7420b8d0355487818c50d",
            "9c9fc42456394adcb492cb0268ba8d95",
            "4b1564b0128941fb8637e15b1bfbdef9",
            "72dfd756bedb4ec9a90abbb6957a8024",
            "53ac4b8c234f4714922e4c85b13ef823",
            "6a691c5cfc7d44ec8731382fa96ed6ca",
            "ab4b34bfdbe2424f9763d3b0c344b1d3",
            "fdfd288019dd40e4868ad21215fa1a67",
            "f27a908af69642279db3f2e495689e41",
            "9f08584874c94c23ac50bdb44bbe1549",
            "5cbd13e97bc44dadad23afcb1fc53aa5",
            "d7cb3b0514c043bbba0729124998ac2c",
            "3f685dbd88a84cdfb8b54d480dcb9755",
            "f355537a85764f96adb3cfbb09a354ce",
            "c51d7eabb9564dc8bacace6526ba3d03",
            "195299d96a2641ac9d77d2f200c0822b",
            "1ced2ddc17c744099f4ea877bf841910",
            "bd1d3658a8aa4ab28c4688862839999b",
            "ecba447751ff465e82403fc8cf34f817",
            "10666c7d28bb49d8aed509f134e5b919",
            "461187bf9c044e8c9fe5aed71a2391f7",
            "62e7508fd2444553a56af5f27c473d95",
            "0ebc734324f24983b5844aa87d2294ad",
            "1c96bd45bb9449a49adafb5ff3515d78",
            "f315bc38d18547b0a604e8c83b223dfa",
            "ef1a0e1b52714894b6628c3b41fef43b",
            "e3dbe8f64a024cc6bed547c475d43366",
            "582001f1d5b94dffb75247f6d1171ade",
            "e01711a47e134dd3b2fdbccfc59b6177",
            "7a30f1a52787477299e0eca4a7aa2957",
            "9222fb236e434282950ad96a454dee93",
            "1b371a8bc41f4b4390fe5041d3791aa9",
            "d74be54104ac4b88ba501a68598ea1e5",
            "6aeb885f477e483c8f7c1753b5ae5e50",
            "8b22e3c616bc4fc6bcb063b3c37c6569",
            "7d8717ecbc5a418d88fe224aea9a82ba",
            "8adf11d28e2b40b984b670a951db2a2b",
            "dbdb63122ef34a759a89fb7a1373d3b8",
            "10db734fc2d14aaa9642004fa67a8cbc",
            "8b78491e7c77481693f189a98313774e",
            "2c8c7331447d43fd8e57d62219719375",
            "66cd264082ca4457adec4df9dacced6f",
            "ef02a06dbb164c3fb5b2fe10cd0b7ab3",
            "6920c709f720419ebb60b4d4918c15c0",
            "fd68cbf2d23b4bdda0b3b6617fb2e18a",
            "e2de696441d0478cb9f40aba50d53a77",
            "e537f47563914c6d8bf0787132562642",
            "fbc175936c214438bdd3852d44ce80a7",
            "91f884234bda437d9d355d13080efb5f",
            "ae15031cfcd44245abf8649222075330",
            "4353f986c91847b38200c51b633b6042",
            "d153b0cade164aa1bef35490fff255a6",
            "934e4017cf8041358231ae40fe016d95",
            "5b85f98078ca4b929a096a44d7c21352",
            "8116461a2bef4933b9161f9949f030a3",
            "3825e5c3666342f18f49b62550ec12e0",
            "6f6e265a2d4e4d8395e4e5f4b5c8ead1",
            "3c4c22bab5834d3198ce9369ead73a29",
            "5cc01da3c1ef45ae85c8789f5356f913",
            "12f8d3d31fec44d79f232c374c4334fe",
            "3be48cb82b4e4c8b9d83d8c25ac8997a",
            "b6808197efcc4ef49546ab102ae35b29",
            "6dbfd58e15504d1ab4de8a4d53097d76",
            "d3419cff507244a6ba321cc24bdc345c",
            "a24a8b7899c74433b245de86d5ee8e0b",
            "5883ce408cb94ccbb42b655341e38cf4",
            "1582627733d34124bec37d148f99de96",
            "d05a8f9605094c39b3cf22d9a4415156",
            "fae6a784baa948d0b71a9e585d0cddeb",
            "982fb88aa5b3460e9c756bed3ca5821b",
            "44e278924c4e42e08b02dda0b696b2a0",
            "b63a71b62ec445ae899b88468eb84094",
            "7e82d8e9087b45dd8e6385c09952d8ae",
            "d54ef66828144247b14e1cf9797582d4",
            "fbe06648afad440e88c48e1a83318b78",
            "64390b584c0849c39eefab29733b9b0d",
            "332aaecbb9fb44e0b41be8a388e2efc1",
            "680075ca103d420cb64519c69da2d5f0",
            "ec25028ff68f4669aa3042b0016d3720",
            "9b0c3d6c090f4e1183c36474f35ed00e",
            "a4dd1a3bd02d46ca8e6c67faf4ea1809",
            "050eb71dc98c4712b47cc84c780dedfb",
            "e36dbd076a5e4f6c9c0ba9b9acd14039",
            "8484330d484b4814a9bf8087453f4403",
            "b7eb158e0dba4cd5bb8a90f80afb6d21",
            "99d4b594c91d43c2adb5d022669b3dcc",
            "0f295ea654c548c8ad26168a829e4ca8",
            "58e0b891a67f4a2b9b6987365680d584",
            "f7c7419a32b64d8491cdd16810052c11",
            "369076808ee84d1baf44105cf0d29f0b",
            "184bb3b6dd184918be5c6b28086a6a39",
            "560eeef0a40b4e6ea1cb74388c788960",
            "6e637dd092fc4b02b73cf305d6407aab",
            "d33aa843597e46db9abe7daef5f6d157",
            "5feac2552dfd49c3af90522d1de0f688",
            "d8588be40a484a5babb9ba16671c9e9a",
            "fc367977803e44b7893454a3a50f133e",
            "0fb72c5f61ca42d9b05a40be12147597",
            "95423b24cd8149759d469ac9654053a0",
            "e527647e06d543ff8a9e1fa2220f4409",
            "4e32f270e828470baede42f7e8284617",
            "6fb61aa8d0da47c194b136941bc5c91c",
            "3f6f812375ca4f0fbeaa0006e29a7ae8",
            "3c46bf9f63f1428cabaac588bbb22cc1",
            "51aeb3cca6614514bffa606dcb9a0ea5",
            "d5e5fbe7a7384873a0b43caeac46beaa",
            "a44b7f412c584cce8b6c35d79ca77a82",
            "80a4870802f44105aa00179f255db7b7",
            "1bbb34be73d842b8872daaed1a3b95c2",
            "d640a8fe8f9f4e9b8125f488e65bebac",
            "2d464130e92b4fbb9455920035df0ec1",
            "b262e3645f7243a4bbac2795a35d812b",
            "075de84ea3eb435b9028f61d812d2351",
            "bdf190fbcf564a8dbd1db2de590443fb",
            "191e91c8bf49422a9242930ff410ab2d",
            "0c073be1255c41a8b74b18348ef9e6fd",
            "bbe5c2b464884469802fb83d97520754",
            "8a10342cc053437988d6835abe5fc6b5",
            "da9a4eac82f04e0f89a9fd17d58e9a6a",
            "c018b471c3b5431cb169c7202f6b8c2e",
            "71cd88e0055b410aa7c4f7a693f9117d",
            "40f12296852946b2a3197757712e0d40",
            "a8a9db9dee894e489e5158fa944325bc",
            "fe279adebf82459cbbc0843a6724cd5c",
            "479f751e7b8a4bac822e4ae460cb090e",
            "6f78ec5c346245f6be985d4ce47d88b8"
          ]
        },
        "id": "4ZAdJASJiJw1",
        "outputId": "bdedc89a-35c7-4236-aa1e-7defed784aa5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BertTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load WMT14 English-German Translation Dataset (test split is enough for our purpose)\n",
        "dataset = load_dataset('wmt14', 'de-en', split='test')\n",
        "\n",
        "# Initialize Tokenizer (use a pretrained tokenizer for simplicity)\n",
        "src_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # English tokenizer\n",
        "tgt_tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')  # German tokenizer\n",
        "\n",
        "# Preprocess data (Tokenization and Padding)\n",
        "def tokenize_data(batch):\n",
        "    src = src_tokenizer(batch['translation']['en'], padding=\"max_length\", truncation=True, max_length=32)\n",
        "    tgt = tgt_tokenizer(batch['translation']['de'], padding=\"max_length\", truncation=True, max_length=32)\n",
        "    return {'src_input_ids': src['input_ids'], 'tgt_input_ids': tgt['input_ids']}\n",
        "\n",
        "dataset = dataset.map(tokenize_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839,
          "referenced_widgets": [
            "9a77ddada08748238c8af063bbd3ae63",
            "799c8313109742258a7eb117d2c73c7b",
            "49f2391b9f494fcab6f650372e803839",
            "38a2b14d67e94912b6428725469eda4c",
            "72f4702b57db4489a9d4cddac3449f3b",
            "bd6f023cd7bf4458856cf9b9b0c72c10",
            "b68bcec7de154dd58677289336a35464",
            "a1bfb913cec54ef5a9f5ce72831e8f46",
            "50eca01e46274b85960bda634e95a6af",
            "54d99fd3f37d49aa96e4de8ece17972a",
            "0b24d861fd5840bca7508cdeb58ffd56",
            "51181d6c7e3440299f1f245f92906a1f",
            "beaa1651b8b6452b94cac5d7a5c7534d",
            "fad2c6b76c74494a8bb808f229eeaa9a",
            "3d05c10da2a540d89af8025dd2246ff5",
            "e919afee81be4809b08f5055b0196aea",
            "1c099afeb3804f31bb6c0a1084ddbc8d",
            "958fb216c04e43beaddaf0c28a913369",
            "c95c8e8cc1d046a382bb41f4ebd59582",
            "13df727664754b15a349c956c5efcc53",
            "8843d60552634643a69dbeab868e2238",
            "2a8e390aa52c423f915bcc9e31239a47",
            "59e176b1f21d44e8942139794fe7ee31",
            "f085a24f2592487b91d0c9dc3f7790f3",
            "ba0f2be29c124910881b5459a2a600b9",
            "1ffb402965a74166b3ef8f898cbff666",
            "cb7d1d57d66043b6b142abb26200837b",
            "82740c92d809421ca6a5fef5469ee1ec",
            "465c9df110a3479da076af1cadb6b836",
            "bcde3c7568424a97996dbe8ac70668bc",
            "1271a2dfd57c493682d8faefe3e50d25",
            "6f6df8d4116545539466a8103376050c",
            "4c5052234df946d8aa1a7e057e12f21e",
            "f048605dd2a347c39d3a1d91cb851dce",
            "866c638d3db94695b14035b7d5711c70",
            "f7a1d15ac05242928c4abcdbbbf56e03",
            "5f300979ac654ab6bfaa924aef5d1392",
            "fbf7b63f6c91476d90a9a9a27d71dd61",
            "7fdbe93b05a44b9cbf6cd2cd0744a515",
            "f93c69a5bebc42048a718969e85f788e",
            "85c15bc5815e4976a64521772db7f142",
            "bbdf808f44c7481c9e894a7c8e196c67",
            "0ff365d33559465dac543e1bae6b2260",
            "b8e9d8efbb1843f7a2b21008474b7638",
            "f17d338f247c44a299e7d5a38580f9c7",
            "199a2d40f75f4cfe98cb798ddf8defe6",
            "3a893c0d4ec94f0a8f59eaf76ebf41be",
            "ed1b336e0dae42cf8f347ccc0cb5383f",
            "faa3eb5df3f14f298a2abc4283fa095a",
            "5f9f3a463a404eec9af1f1efa30320c0",
            "d6059c5a370e4d539bd8468098de5c5d",
            "da456ffb12814a3b811a41f2e5cf5ed6",
            "490e1c30174c48b5bdd8f0ce163548ae",
            "2284e069261d4587a11794230c2e4bed",
            "d06712cd9f454ec1ac9e6ad2d6f84bb2",
            "b3e40a85b407405aae30ba5338fa708e",
            "ed8d43c4cd0c4650b66cb778e0b9d70d",
            "1e4280c8cf7e48ea9391379bf2931bb7",
            "08dee09982964985ba3ef10219f544ef",
            "ab9eaf36522240c4953805d47236e0fa",
            "4890da302445404b983842a004039b84",
            "7bf881a9ff2945e09b4c6ca630970eda",
            "785b69f9a684402ba0acedeacf6042ff",
            "2dfa1a2dcc6d43a183051bee0fe158c6",
            "fb5c762a74b1456fbadc2c8340fa443a",
            "0732c2b645034fa2b5606a0ab10f9ca2",
            "8bc61dcdeb1742d19cb53e2c766eed58",
            "dbc630cb5b2a42759f56fad052703c37",
            "8420bed5946641bbb07b299fbb1b2d53",
            "f6ac1a6473f04c53acfef41904faf8bd",
            "04d0718b08d44c018523ba6e954c54a4",
            "7ea569121b7d4a62b86c52b0281568a5",
            "93246ca44a214826831a52de3631c862",
            "6630e124b59b4d20a53f19fa370b70b8",
            "d912e9a7b9ba4648a7bd282a97790fae",
            "b520b682b6604a34b3c8acac0abdbe96",
            "d5df7882e7a24aeaa16cebbd8634bacf",
            "77f3b610079647a2abd46642701fc22a",
            "5a04b43862ab47fe84deed71b4fbc283",
            "a98fdf0d735f493b9a39548a54eab7a9",
            "223b4dc65d894ac7ad4d785275578374",
            "cf78dbf48edb4e1fac62a586eba19f29",
            "a224519cb50248e6b78765b20f2ef65d",
            "24fdbfbfa88a45b49814e9cf5b9b375e",
            "e228939cff614f95974c6ee1527c4c36",
            "3853dc21d13c4fee940c7b85ac8393cd",
            "53441d1249c548eea6c53faaf03c60e2",
            "3b6384246f77411190945fd29533ccc2",
            "3357e54a20234de0ae3001232d11bac5",
            "bcef5220237944139750bf30a7549309",
            "a3c67e69980841b5b3acf7cdfa43e605",
            "580035592ac94c1a96faf0e466510b0d",
            "d6102e9b35774927bcf796179740fa51",
            "b949c45d20b04dbc8c4fd5aae9fdf4ec",
            "2375901547d344bf9f1b5b17e8303677",
            "2503a8ac1a7e45269c1d0f412600b925",
            "006292db342749e0a0b60c6ebfd52b76",
            "5809f62174a440e6a816281a8e1469dc",
            "1d649a48a01d4fe38d308d087b9587fb",
            "70a821f2b7d14477bfb92ad74329e263",
            "b1a642762a134e48bb759b780ab227de",
            "ebed81dbca0f4dc6a89b399ef4b92c89",
            "e952244409ee412383abf2cce2403819",
            "8dffc40d5d914a4aa3259ed5a893badc",
            "71e0d3290ca74b7d876e3ce3d1ef6311",
            "81f8886d78c24132a6101dc57e277e33",
            "4c66cb57595945028bed39fdcfca7e66",
            "1dc43c22adef4ad48faa72851c51b95f",
            "438cc5bc69ea4491a8de4d13b8c709d7",
            "ff93050903b24faeb2be4f285c3dc4b3",
            "378ae7970c174a8c944c0afdaf410f46",
            "039a11c6b1264b5eac363b117000ef60",
            "4ba59a289a8f4fcdb7ea180a0b6ba267",
            "232ad8247d454d96a3ddf239ba11afbe",
            "bbe16190d296471fa74ea546ce36da1c",
            "008a59742a6c41598fb18d12b0ba0067",
            "c5e8f8cf1df5416b9d595ebcb17db79c",
            "d5a188cf4ae5423788353d6818d595c2",
            "16e7a69a7602477c94a1978612b46ff4",
            "1880f057443c456496f9a4690eac9639",
            "4e5ef65176b14dd887f2d0e9d060c388",
            "3b152c6fabb84f0c9aa7e5fa8bb63f18",
            "6a3d145972aa4112b85489dfb0e83fbf",
            "35a5ced8c28044fa9720f79cdded81f8",
            "a10f16b95c064f0a88bccfe38019c208",
            "7209910792a74e8992a8c357e247bc8f",
            "83925cf904204ef99896e33a1ed513b1",
            "f6b19ec505ed4577af9dcabde46f3e87",
            "13f00b20c286412a9ba141450e263f60",
            "a7f484b39fdf4e1490595b83736e274b",
            "2cd5b98c01dc43a8aa7c3b434f598af8",
            "1d426d507f0645d592345d803ce39b64",
            "f435bac7a07d42c497a8641f94795b2c",
            "ab67614a27b64f5ba9aa2370045d38e2",
            "5964b3515a4247f1b818903fa6c59ce7",
            "af46ddd969344daa9dc9d195b64ba9ba",
            "6fcf7f08efd747a0b0d539231d618658",
            "03c9826b0e534ca985cefb9839c593f7",
            "9d4d5d04b3624158946796ee29639a2c",
            "74b0fe88fbc44404bf79eecb0c2efe44",
            "7ad067f1e49048959689587598a2dd99",
            "469ea27ce35042ce88e5ddbea80dedb0",
            "d9cf2dab16f840408d265ab353ec4d97",
            "51a245a56721471582ae7433eb5911cb",
            "f71baeef7212404f963dd81379a9064b",
            "2d7acd5c6baa484087d3196b86929005",
            "6412407d8e5c4907aad0f1fa8d3e5523",
            "0cba9652c12b4ff9904930860a21547b",
            "0b1e94fd90694a6abdd9e9b08492a389",
            "8b3f4d0c29864ac792629af4ed234707",
            "2bd61716e314433084f7c3dcd8e1db76",
            "a9490878dede42af92f435ba184d2521",
            "13342a4aac8f410d950747813c4c461d",
            "24dad8036b99430dba3769bd93a5ec9f",
            "af68fc32372342dcb9516fd149fa8143",
            "625b23ef614d4d028b8f7043f7623436",
            "22ba05370f2242ca928824cfc42a86dc",
            "77a8aec7932e4496b7db34291f9760b2",
            "667ef72183804c008838cf04be1768dd",
            "9bb4f21068954ac9b4167c81c74f21c8",
            "2df2be5baf5c48fc9098f91c8a087db6",
            "0bb56bff0f2947b9b4c6998b1ddb4f66",
            "763093a030e24a78b6914558c2a60202",
            "fbe9a02ad40544d083355df41c7000ea",
            "23b5ca8a923a47809060861187ae6e3c",
            "3b6f084a35094588bd892a8bb108e9f6",
            "7f036f053a134710bb0decff2ad33c94",
            "65af592c5ea949c3999fc6effa8c4f1f",
            "6faaaf609564460abd4b129a18c61033",
            "259b448dddc74ea786c64ebb3b6aa4a5",
            "1053ea3ef8cb49408b9951e33044c2ed",
            "97c161e692f644109298df2e2ad8e820",
            "b1e0556a168848b38c7279671182886b",
            "4c55c93e2b1d4e0e8df309d82037a33e",
            "f6155011a6074125b58085d4165badc0",
            "5dd9e57c56684972a93d1049ef59b06d",
            "f4fc3e82b02d49ecb3cc39e4f34565d3",
            "6904cbf941e34238a955e4bc2ab75d38",
            "9fac8d578bb4445e98e6f18615b3fa71",
            "de5fb7394dd14dafbd8c7663bef87014",
            "9e4ee0868a2d4a658510157fdc380e18",
            "798157b2fb7c4d4faaf44a1f3081a9fd",
            "f33711a9275e457ca96366effc77d2d9",
            "92d3e34f49bf4b72bead49ec128e73e0",
            "166074c774774bf5ac91a515be9c88f5",
            "733943c87b7f4ea0947e34dea485ed67",
            "3e275708ecec44f49115ec1d80c3da2c",
            "ae010784df5342e6b72e5f63f14316f7",
            "12236507d74d452599ff2858d51e7289",
            "9d2695ccea2d48b7b03040c26bb4e229",
            "f3113cb048c043fba48beeb2ebadd67d",
            "6c3475addbfe46628120008f0edf325c",
            "868b5e66a17d431dbe9a4cca2b554655",
            "3b6a9e6249b74420931311e7f75f4b69",
            "c28e4f9e2ada4bf1b058ec261b101a36",
            "6665be7ee3024d22b4d57837f791177e",
            "811cb30221434dd4992cd04151be357d",
            "1032f81634bf4289b893aa76e371554e",
            "c6d47f5ed80a447a8fff098af46646d2",
            "1f3dd0c9afd643518a51da32f8aa8a0e",
            "86b785f422514ca2bc8e7541caf38410",
            "a2c4c64b72ea48f3ba66cdae418d839d",
            "8623c59683894a219e684c66346dc619",
            "17c017ea6281454daaa3a8e36dbaf270",
            "0d1f22bcbca043c59df1d2b2044dde58",
            "dc40c203224848bdb6383ab4a483a430",
            "39fc237beb0a409b904f64044f98db64",
            "f7808906dd574c23851fc3135c9a02b5",
            "08b24c1ca7654601a1ab7e59a98ae4e4",
            "1b84fb0a74a44719a031c5821547732b",
            "9ea4d02d97f747069378d6b1e9c36f81",
            "4f9a61fe5539497baf139f3631d2d8c1",
            "f2dd1120d20f4e32a1401b023e857132",
            "a6436529a1704615a603067d2411e9bb",
            "7cfbc18fc9e3480295afe0df15b6347e",
            "c0909d71a7e44d67a98a5054c3dd3df9",
            "350a18fa546e408f9b5fddfef52d39b3",
            "485981602aa945359d897c586e554071",
            "85eedadf6f914b9ab0b0be125822b119",
            "f7477fd140b9449fb44d57b10b19468f"
          ]
        },
        "id": "TZuW9wcJt7wQ",
        "outputId": "e1f11dc6-0f6f-4dc7-bf90-4aa46cbbf5f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a77ddada08748238c8af063bbd3ae63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51181d6c7e3440299f1f245f92906a1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train loss: 0.31039235210418703, Val loss: 0.3036927996223731\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59e176b1f21d44e8942139794fe7ee31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f048605dd2a347c39d3a1d91cb851dce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train loss: 0.2900807647705078, Val loss: 0.28730585567972594\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17d338f247c44a299e7d5a38580f9c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3e40a85b407405aae30ba5338fa708e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train loss: 0.27304628705978395, Val loss: 0.27424413637292466\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bc61dcdeb1742d19cb53e2c766eed58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77f3b610079647a2abd46642701fc22a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Train loss: 0.25954092693328856, Val loss: 0.2641999006033657\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3357e54a20234de0ae3001232d11bac5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70a821f2b7d14477bfb92ad74329e263",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Train loss: 0.24909723782539367, Val loss: 0.256743199090777\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "378ae7970c174a8c944c0afdaf410f46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b152c6fabb84f0c9aa7e5fa8bb63f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Train loss: 0.2414636206626892, Val loss: 0.25176503532310784\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f435bac7a07d42c497a8641f94795b2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51a245a56721471582ae7433eb5911cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Train loss: 0.2363039960861206, Val loss: 0.2488588759098072\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af68fc32372342dcb9516fd149fa8143",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b6f084a35094588bd892a8bb108e9f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Train loss: 0.2330855667591095, Val loss: 0.24725568472804244\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4fc3e82b02d49ecb3cc39e4f34565d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae010784df5342e6b72e5f63f14316f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Train loss: 0.23094035577774047, Val loss: 0.2462076589331432\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6d47f5ed80a447a8fff098af46646d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b84fb0a74a44719a031c5821547732b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Train loss: 0.22944898128509522, Val loss: 0.245560116449358\n"
          ]
        }
      ],
      "source": [
        "# Set vocab sizes\n",
        "src_vocab_size = src_tokenizer.vocab_size\n",
        "tgt_vocab_size = tgt_tokenizer.vocab_size\n",
        "\n",
        "# Define model parameters\n",
        "src_seq_len = 32  # Max length of source sequences\n",
        "tgt_seq_len = 32  # Max length of target sequences\n",
        "d_model = 512\n",
        "N = 6  # Number of layers\n",
        "h = 8  # Number of heads\n",
        "dropout = 0.1\n",
        "d_ff = 2048\n",
        "\n",
        "# Build Transformer Model\n",
        "transformer = build_transformer(src_vocab_size, tgt_vocab_size, src_seq_len, tgt_seq_len, d_model, N, h, dropout, d_ff).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = CrossEntropyLoss(ignore_index=0)  # Ignore padding index\n",
        "optimizer = Adam(transformer.parameters(), lr=2e-5)\n",
        "\n",
        "def create_src_mask(src_input, pad_idx=0):\n",
        "    \"\"\"Create a mask for the source to hide padding tokens.\"\"\"\n",
        "    src_mask = (src_input != pad_idx).unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, seq_len)\n",
        "    return src_mask\n",
        "\n",
        "def create_tgt_mask(tgt_input, pad_idx=0):\n",
        "    \"\"\"Create a target mask to hide future tokens (causal mask) and padding tokens.\"\"\"\n",
        "    batch_size, tgt_len = tgt_input.shape\n",
        "    # Causal mask to prevent looking ahead\n",
        "    causal_mask = torch.tril(torch.ones(tgt_len, tgt_len)).bool().to(tgt_input.device).unsqueeze(0)  # (1, tgt_len, tgt_len)\n",
        "    # Padding mask\n",
        "    pad_mask = (tgt_input != pad_idx).unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, tgt_len)\n",
        "\n",
        "    # Combine the causal mask and padding mask\n",
        "    tgt_mask = causal_mask & pad_mask.squeeze(1)  # (batch_size, tgt_len, tgt_len)\n",
        "    return tgt_mask.unsqueeze(1)  # (batch_size, 1, tgt_len, tgt_len)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(10):\n",
        "    transformer.train()\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    transformer.train()\n",
        "    # Training\n",
        "    for i in tqdm(range(0, 2000, 32)):\n",
        "        src_input = torch.tensor(dataset[i:i+32]['src_input_ids']).to(device)\n",
        "        tgt_input = torch.tensor(dataset[i:i+32]['tgt_input_ids']).to(device)\n",
        "\n",
        "        # Create masks\n",
        "        src_mask = create_src_mask(src_input).to(device)\n",
        "        tgt_mask = create_tgt_mask(tgt_input[:, :-1]).to(device)  # Apply mask only on the decoder input sequence\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        encoder_output = transformer.encode(src_input, src_mask)\n",
        "        decoder_output = transformer.decode(encoder_output, src_mask, tgt_input[:, :-1], tgt_mask)\n",
        "        output = transformer.project(decoder_output)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output.view(-1, tgt_vocab_size), tgt_input[:, 1:].reshape(-1))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    transformer.eval()\n",
        "    # Evaluation\n",
        "    for i in tqdm(range(2000, len(dataset), 32)):\n",
        "        with torch.no_grad():\n",
        "            src_input = torch.tensor(dataset[i:i+32]['src_input_ids']).to(device)\n",
        "            tgt_input = torch.tensor(dataset[i:i+32]['tgt_input_ids']).to(device)\n",
        "\n",
        "            # Create masks\n",
        "            src_mask = create_src_mask(src_input).to(device)\n",
        "            tgt_mask = create_tgt_mask(tgt_input[:, :-1]).to(device)  # Apply mask only on the decoder input sequence\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            encoder_output = transformer.encode(src_input, src_mask)\n",
        "            decoder_output = transformer.decode(encoder_output, src_mask, tgt_input[:, :-1], tgt_mask)\n",
        "            output = transformer.project(decoder_output)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output.view(-1, tgt_vocab_size), tgt_input[:, 1:].reshape(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train loss: {train_loss/2000}, Val loss: {val_loss/(len(dataset) - 2000)}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
