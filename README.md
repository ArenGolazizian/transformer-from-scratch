# Transformer from scratch

Transformers have revolutionized the field of Natural Language Processing (NLP) by introducing a novel mechanism for capturing dependencies within sequences through attention mechanisms. 

This project implements the Transformer model from scratch using PyTorch, based on the paper: [*Attention Is All You Need!*](https://arxiv.org/abs/1706.03762).

## ğŸ“Œ Features

- Implements a full Transformer architecture with encoder and decoder blocks
- Includes multi-head attention, positional encoding, feedforward networks, and residual connections
- Trains on the WMT14 English-German translation dataset (test split used for demonstration)
- Customizable hyperparameters for experimentation

## ğŸ“Š Results
### Training Log Summary
| Epoch | Train Loss | Validation Loss |
|-------|-----------|----------------|
| 1     | 0.3104    | 0.3037         |
| 2     | 0.2901    | 0.2873         |
| 3     | 0.2730    | 0.2742         |
| 4     | 0.2595    | 0.2642         |
| 5     | 0.2491    | 0.2567         |
| 6     | 0.2415    | 0.2518         |
| 7     | 0.2363    | 0.2489         |
| 8     | 0.2331    | 0.2473         |
| 9     | 0.2309    | 0.2462         |
| 10    | 0.2294    | 0.2456         |

ğŸ”¹ **Final Validation Loss:** `0.2456`  
ğŸ”¹ **Training Log:** Available in [`results/train_logs.txt`](results/train_logs.txt)

## ğŸ“‚ Project Structure
```plaintext
transformer-from-scratch/
â”‚â”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ dataset.py         # Data processing
â”‚   â”œâ”€â”€ model.py           # Transformer implementation
â”‚   â”œâ”€â”€ train.py           # Training script (loss, optimizer,training loop)
â”‚   â”œâ”€â”€ evaluate.py        # Evaluation script (mask functions and evaluation loop)
â”‚â”€â”€ notebooks/             # Jupyter Notebook experiments
â”‚   â”œâ”€â”€ transformer-from-scratch.ipynb
â”‚â”€â”€ results/               # Logs and evaluation outputs
â”‚   â”œâ”€â”€ train_logs.txt     # Training logs
â”‚â”€â”€ README.md              # Project overview (this file)
â”‚â”€â”€ requirements.txt       # Dependencies list
```

## ğŸ“¦ Installation & Setup

Follow these steps to set up the project:

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/ArenGolazizian/your-repository-name.git
cd your-repository-name
```
###2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 3ï¸âƒ£ Run Training
```bash
python src/train.py
```
### 4ï¸âƒ£ Evaluate Model
```bash
python src/evaluate.py
```
Open transformer-from-scratch.ipynb to explore the implementation.